{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Libraries we'll need \n",
    "from collections import Counter\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn import datasets, neighbors, linear_model\n",
    "from sklearn.svm import SVC\n",
    "import scipy.stats\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import string\n",
    "import re\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from collections import defaultdict\n",
    "import operator\n",
    "import csv\n",
    "from PorterStemmer import PorterStemmer\n",
    "import random\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from nltk import pos_tag"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reading in data - train and dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('fixed_combined_train_files_plscommas.csv',encoding='utf8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dev = pd.read_csv('fixed_combined_dev_files.csv',encoding='utf8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Selecting appropriate columns - train and dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = df[['sentence','gender']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dev = df_dev[['sentence','gender']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((869536, 2), (125950, 2))"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train.shape, data_dev.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocessing - Removing punctuation, Porter Stemming, and lowercasing \n",
    "\n",
    "Note: Must recount unigram and bigram frequencies for each type of preprocessed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_punctuations(text):\n",
    "    for punctuation in string.punctuation:\n",
    "        #text = str(text).encode('utf-8').replace(punctuation, ' ')\n",
    "        text = text.replace(punctuation, ' ')\n",
    "    #text = re.sub( '\\s+', ' ', text ).encode('utf-8').strip()\n",
    "    text = re.sub( '\\s+', ' ', text ).strip()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "def porter_stem(text):\n",
    "    p = PorterStemmer()\n",
    "    return p.stem(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lower(text):\n",
    "    return text.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cell below: exclusively for choosing a preprocessing technique\n",
    "\n",
    "5/28/2018 1:35pm REMOVE PUNCTUATION AS PREPROCESSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/pandas/core/indexing.py:621: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[item_labels[indexer[info_axis]]] = value\n"
     ]
    }
   ],
   "source": [
    "data_train.loc[:, 'sentence'] = data_train.loc[:, 'sentence'].apply(remove_punctuations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/pandas/core/indexing.py:621: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[item_labels[indexer[info_axis]]] = value\n"
     ]
    }
   ],
   "source": [
    "data_dev.loc[:, 'sentence'] = data_dev.loc[:, 'sentence'].apply(remove_punctuations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/pandas/core/indexing.py:621: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[item_labels[indexer[info_axis]]] = value\n"
     ]
    }
   ],
   "source": [
    "data_train.loc[:, 'sentence'] = data_train.loc[:, 'sentence'].apply(lower)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/pandas/core/indexing.py:621: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[item_labels[indexer[info_axis]]] = value\n"
     ]
    }
   ],
   "source": [
    "data_dev.loc[:, 'sentence'] = data_dev.loc[:, 'sentence'].apply(lower)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Functions for collecting unigram and bigram frequencies - must call every time a new preprocessing technique is applied "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_unigrams():\n",
    "    all_unigrams = {}\n",
    "    #for every row in the dataframe, get the text of the sentence column, tokenize it, and count every token in it \n",
    "    for index, row in data_train.iterrows():\n",
    "        text = row['sentence']\n",
    "        words = word_tokenize(text)\n",
    "        for word in words:\n",
    "            all_unigrams[word] = all_unigrams.get(word,0) + 1\n",
    "    sorted_unigrams = sorted(all_unigrams.items(), key=operator.itemgetter(1), reverse=True)\n",
    "    return sorted_unigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_bigrams():\n",
    "    all_bigrams = {}\n",
    "    for index, row in data_train.iterrows():\n",
    "        text = row['sentence']\n",
    "        words = ['<S>'] + word_tokenize(text) + ['</S>']\n",
    "        for i in range(1, len(words)):\n",
    "            bi = words[i-1] + \" \" + words[i]\n",
    "            all_bigrams[bi] = all_bigrams.get(bi,0) + 1\n",
    "    sorted_bigrams = sorted(all_bigrams.items(), key=operator.itemgetter(1), reverse=True)\n",
    "    return sorted_bigrams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Actually collecting frequencies for model being run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "unigram_frequencies = sort_unigrams()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigram_frequencies = sort_bigrams()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "115933"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(unigram_frequencies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3146374"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(bigram_frequencies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting the top 5k unigrams for use as features in the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_unigrams = {uni[0]: uni[1] for uni in unigram_frequencies[:10000]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_bigrams = {bi[0]: bi[1] for bi in bigram_frequencies[:10000]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(top_unigrams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(top_bigrams)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Featurizing functions: unigrams, bigrams, unigrams + bigrams, all the rest applied to POS and lemma, LIWC lists, HBR lexicons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "# given sentence, and list of top unigrams and bigrams\n",
    "# returns feature dicts for unigrams and bigrams\n",
    "def unigrams(text):\n",
    "    words = word_tokenize(text)\n",
    "    final = {}\n",
    "    \n",
    "    for word in words:\n",
    "        if word in top_unigrams:\n",
    "            final[word] = final.get(word,0) + 1\n",
    "        else:\n",
    "            final['UNK'] = final.get('UNK',0) + 1\n",
    "    return final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "def all_unigrams(text):\n",
    "    words = word_tokenize(text)\n",
    "    final = {}\n",
    "    \n",
    "    for word in words:\n",
    "        final[word] = final.get(word,0) + 1\n",
    "    return final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bigrams(text):\n",
    "    words = ['<S>'] + word_tokenize(text) + ['</S>']\n",
    "    final = {}\n",
    "    \n",
    "    for i in range(1, len(words)):\n",
    "        bi = words[i-1] + \" \" + words[i]\n",
    "        if bi in top_bigrams:\n",
    "            final[bi] = final.get(bi,0) + 1\n",
    "        else:\n",
    "            final['UNK UNK'] = final.get('UNK UNK',0) + 1\n",
    "    return final "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pos_unigrams(text):\n",
    "    words = word_tokenize(text)\n",
    "    tags = [pair[1] for pair in pos_tag(words)]\n",
    "    final = {}\n",
    "    for tag in tags:\n",
    "        final[tag] = final.get(tag,0)+1\n",
    "    return final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Actually featurizing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_dicts_train = []\n",
    "labels_train = []\n",
    "for index, row in data_train.iterrows():\n",
    "    text = row['sentence']\n",
    "    label = row['gender']\n",
    "    feature_dict = all_unigrams(text)\n",
    "    feat_dicts_train.append(feature_dict)\n",
    "    labels_train.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_dicts_dev = []\n",
    "labels_dev = []\n",
    "for index, row in data_dev.iterrows():\n",
    "    text = row['sentence']\n",
    "    label = row['gender']\n",
    "    feature_dict = all_unigrams(text)\n",
    "    feat_dicts_dev.append(feature_dict)\n",
    "    labels_dev.append(label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Converting dictionary of dictionaries to matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = DictVectorizer(sparse=True)\n",
    "features_train = vectorizer.fit_transform(feat_dicts_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_dev = vectorizer.transform(feat_dicts_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((869536, 115933), 869536, (125950, 115933), 125950)"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_train.shape, len(labels_train), features_dev.shape, len(labels_dev)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optional: re-weighted features_train and features_dev with tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_transformer = TfidfTransformer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_train_tfidf = tfidf_transformer.fit_transform(features_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_dev_tfidf = tfidf_transformer.transform(features_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((869536, 115933), (125950, 115933))"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_train_tfidf.shape,features_dev_tfidf.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instantiating and training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convergence after 24 epochs took 24 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   24.5s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   24.5s finished\n"
     ]
    }
   ],
   "source": [
    "logistic = LogisticRegression(verbose=3,solver='sag')\n",
    "log_model = logistic.fit(features_train_tfidf,labels_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predicting on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic_predictions = logistic.predict(features_dev_tfidf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting the numbers!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic regression result: \n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "     female       0.69      0.25      0.37     31498\n",
      "       male       0.79      0.96      0.87     94452\n",
      "\n",
      "avg / total       0.77      0.78      0.75    125950\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Logistic regression result: \")\n",
    "print(classification_report(labels_dev, logistic_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Figuring out the most informative features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = list(log_model.coef_.transpose())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_dict = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name,weight in zip(names,weights):\n",
    "    weight_dict[name] = weight[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_weights = sorted(weight_dict.items(), key=operator.itemgetter(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('husband', -12.519585344458351),\n",
       " ('ms', -10.866351627147916),\n",
       " ('woman', -9.413209045501345),\n",
       " ('mrs', -8.549631262560471),\n",
       " ('actress', -7.535076350705512),\n",
       " ('devos', -7.395482305563533),\n",
       " ('lady', -7.271073993325328),\n",
       " ('girl', -6.7886979195848385),\n",
       " ('beyonc√©', -6.3699398872525235),\n",
       " ('hijab', -6.186432974792667),\n",
       " ('server', -5.991395252412696),\n",
       " ('pregnancy', -5.633379477612983),\n",
       " ('lanashadwick2', -5.477710084907814),\n",
       " ('pregnant', -5.36039868700924),\n",
       " ('madonna', -5.325174553374608),\n",
       " ('boyfriend', -5.315579805206431),\n",
       " ('erdely', -5.293358539656793),\n",
       " ('lock', -5.255381022274753),\n",
       " ('feminist', -5.213592571622445),\n",
       " ('female', -5.178309871689569),\n",
       " ('hillary', -5.121758370390941),\n",
       " ('haley', -5.067249478548496),\n",
       " ('queen', -4.839592975104978),\n",
       " ('chairwoman', -4.826944014459833),\n",
       " ('daughter', -4.698547272526667),\n",
       " ('meldonium', -4.674419945066522),\n",
       " ('congresswoman', -4.5618650476939075),\n",
       " ('chancellor', -4.430826971163066),\n",
       " ('heroine', -4.417530207189577),\n",
       " ('streep', -4.398426397864497),\n",
       " ('gymnast', -4.393872485254443),\n",
       " ('chappaqua', -4.324933526723683),\n",
       " ('mother', -4.323399870813585),\n",
       " ('feminism', -4.28867957120476),\n",
       " ('princess', -4.263707976986328),\n",
       " ('fiance', -4.214702658481388),\n",
       " ('lesbian', -4.136670808636302),\n",
       " ('vogue', -4.1315570076501),\n",
       " ('headscarf', -4.128260337743453),\n",
       " ('handel', -4.039218929138301),\n",
       " ('pneumonia', -4.037924450732399),\n",
       " ('raped', -4.031231414072654),\n",
       " ('trustworthiness', -3.9909203569686778),\n",
       " ('firsthillary', -3.9369744975810597),\n",
       " ('mom', -3.924215748690733),\n",
       " ('blackberry', -3.9118269018286327),\n",
       " ('businesswoman', -3.8998786126958125),\n",
       " ('electionhillary', -3.8458616234877665),\n",
       " ('benghazi', -3.84367228898088),\n",
       " ('bjkingape', -3.8412224878765815)]"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_weights[:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('warmbier', 3.090945335205684),\n",
       " ('potro', 3.097216598590564),\n",
       " ('scalia', 3.1117348648052103),\n",
       " ('blasio', 3.1128110112194856),\n",
       " ('priebus', 3.137806778589711),\n",
       " ('netanyahu', 3.138601069914844),\n",
       " ('zuckerberg', 3.152385919129663),\n",
       " ('christie', 3.1773271754428096),\n",
       " ('farage', 3.205149555119673),\n",
       " ('nba', 3.2725419916498395),\n",
       " ('comey', 3.356732063840973),\n",
       " ('ryan', 3.3589080888458263),\n",
       " ('nato', 3.4560851202670824),\n",
       " ('joelpollak', 3.4771038785849613),\n",
       " ('duterte', 3.482991006568131),\n",
       " ('xi', 3.4837291793789564),\n",
       " ('president', 3.5061725669599078),\n",
       " ('congressman', 3.5368469000280203),\n",
       " ('innings', 3.54729249139483),\n",
       " ('awr', 3.56266112833162),\n",
       " ('kaepernick', 3.6031980801854857),\n",
       " ('treasury', 3.607637968008508),\n",
       " ('jets', 3.6163108595596394),\n",
       " ('warriors', 3.623724305272961),\n",
       " ('boy', 3.643661624302862),\n",
       " ('beard', 3.673143384117225),\n",
       " ('romney', 3.7489711234958896),\n",
       " ('nfl', 3.8010419736926266),\n",
       " ('businessman', 3.8114877695025084),\n",
       " ('cruz', 3.881700131894629),\n",
       " ('giants', 3.9020999816002697),\n",
       " ('mrnashington', 3.902862188040042),\n",
       " ('sessions', 3.9379337785359483),\n",
       " ('ali', 3.9545580596510694),\n",
       " ('breitbart', 4.0244110667996775),\n",
       " ('pence', 4.110495469562074),\n",
       " ('musk', 4.123881412585761),\n",
       " ('quarterback', 4.1358281436911515),\n",
       " ('knicks', 4.234719101745873),\n",
       " ('milo', 4.321673417837595),\n",
       " ('prince', 4.353596895881112),\n",
       " ('regnery', 4.639055239070054),\n",
       " ('yankees', 4.666900656472831),\n",
       " ('man', 5.026735437944864),\n",
       " ('guy', 5.093559782157809),\n",
       " ('rubio', 5.438996250139622),\n",
       " ('mets', 5.476188209307665),\n",
       " ('trump', 6.241185621001806),\n",
       " ('wife', 6.834887770758549),\n",
       " ('mr', 8.077346609234915)]"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_weights[-50:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
